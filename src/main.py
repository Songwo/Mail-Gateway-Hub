import asyncio
import argparse
import json
import sqlite3
import sys
import traceback
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
from typing import List, Dict, Any, Optional

import requests
import google.generativeai as genai
from imap_tools import MailBox, AND
from loguru import logger

# ===========================
# 0. å…¨å±€å˜é‡ä¸æ—¥å¿—é…ç½®
# ===========================
SCRIPT_START_TIME = datetime.now()
DB_PATH = "mail_gateway.db"
CONFIG_FILE = "config.json"

logger.remove()
logger.add(sys.stdout, colorize=True, format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{message}</cyan>")
logger.add("mail_gateway.log", rotation="10 MB", retention="7 days")

# ===========================
# 1. æ ¸å¿ƒé…ç½®ä¸æ•°æ®åº“
# ===========================
def load_config() -> Dict:
    try:
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        logger.error(f"âŒ [CONFIG] é…ç½®æ–‡ä»¶ '{CONFIG_FILE}' æœªæ‰¾åˆ°ï¼")
        sys.exit(1)

def init_db():
    with sqlite3.connect(DB_PATH) as conn:
        conn.execute('''
            CREATE TABLE IF NOT EXISTS processed_emails (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                account_email TEXT NOT NULL,
                alias TEXT,
                uid TEXT NOT NULL,
                category TEXT,
                summary TEXT,
                processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(account_email, uid)
            )
        ''')
        try:
            conn.execute("ALTER TABLE processed_emails ADD COLUMN alias TEXT")
        except sqlite3.OperationalError:
            pass 

def is_processed(email: str, uid: str) -> bool:
    with sqlite3.connect(DB_PATH) as conn:
        cur = conn.cursor()
        cur.execute("SELECT 1 FROM processed_emails WHERE account_email=? AND uid=?", (email, uid))
        return cur.fetchone() is not None

def save_result(email: str, alias: str, uid: str, ai_result: Dict):
    with sqlite3.connect(DB_PATH) as conn:
        conn.execute("""
            INSERT OR IGNORE INTO processed_emails 
            (account_email, alias, uid, category, summary) 
            VALUES (?, ?, ?, ?, ?)
        """, (email, alias, uid, ai_result.get('category'), ai_result.get('summary')))

def get_db_stats(limit=15):
    with sqlite3.connect(DB_PATH) as conn:
        conn.row_factory = sqlite3.Row
        cursor = conn.execute("SELECT * FROM processed_emails ORDER BY processed_at DESC LIMIT ?", (limit,))
        return [dict(row) for row in cursor.fetchall()]

# ===========================
# 2. å¼‚æ­¥ IO åŒ…è£… (AI & æ¨é€)
# ===========================
executor = ThreadPoolExecutor(max_workers=10)

async def async_call_gemini(content: str, config: Dict) -> Dict:
    loop = asyncio.get_running_loop()
    return await loop.run_in_executor(executor, _sync_call_gemini, content, config)

def _sync_call_gemini(content: str, config: Dict) -> Dict:
    api_key = config.get("gemini_api_key")
    if not api_key:
        return {"category": "æœªé…ç½®AI", "summary": "æœªé…ç½® Gemini API Key", "priority": 1}
    
    genai.configure(api_key=api_key)
    
    target_models = ['gemini-1.5-flash-latest', 'gemini-1.5-flash', 'gemini-pro']
    model_to_use = "gemini-1.5-flash-latest"
    
    try:
        # å°è¯•å‘ç°å¯ç”¨æ¨¡å‹
        available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        for tm in target_models:
            if f"models/{tm}" in available_models:
                model_to_use = tm
                break
        
        model = genai.GenerativeModel(model_to_use)
        prompt = f"{config.get('system_prompt', '')}\nEmail Content: {content[:3000]}\nOutput JSON ONLY."
        resp = model.generate_content(prompt)
        text = resp.text.replace('```json', '').replace('```', '').strip()
        return json.loads(text)
    except Exception:
        logger.error(f"âŒ [AI] Gemini è°ƒç”¨å¤±è´¥ (å°è¯•æ¨¡å‹: {model_to_use})")
        logger.error(traceback.format_exc())
        return {"category": "AI Error", "summary": "è§£æå¤±è´¥", "priority": 1}

async def async_send_feishu(msg_data: Dict, ai_result: Dict, config: Dict, account_cfg: Dict):
    loop = asyncio.get_running_loop()
    await loop.run_in_executor(executor, _sync_send_feishu, msg_data, ai_result, config, account_cfg)

def _sync_send_feishu(msg_data: Dict, ai_result: Dict, config: Dict, account_cfg: Dict):
    webhook = config.get("feishu_webhook")
    if not webhook: return

    alias = account_cfg.get('alias', 'é»˜è®¤')
    category = ai_result.get('category', 'å…¶ä»–')
    is_urgent = category in ["éªŒè¯ç ", "é‡è¦é€šçŸ¥"] or ai_result.get('priority', 0) >= 4
    header_color = "red" if is_urgent else "blue"
    
    email = account_cfg['email']
    summary = ai_result.get('summary', 'æ— æ‘˜è¦')
    v_code = ai_result.get('verification_code')
    
    content_md = f"**æ‘˜è¦**: {summary}\n**å‘ä»¶äºº**: {msg_data['from']}"
    if v_code and str(v_code).lower() != "null":
        content_md += f"\n\n**éªŒè¯ç **: <font color='red'>{v_code}</font>"

    payload = {
        "msg_type": "interactive",
        "card": {
            "config": {"wide_screen_mode": True},
            "header": {
                "template": header_color,
                "title": {"tag": "plain_text", "content": f"[{alias}] {msg_data['subject']}"}
            },
            "elements": [
                {"tag": "div", "text": {"tag": "lark_md", "content": content_md}},
                {"tag": "hr"},
                {
                    "tag": "note", 
                    "elements": [
                        {"tag": "plain_text", "content": f"ğŸ“ èº«ä»½: {alias} | è´¦å·: {email}\nğŸ¤– ç”± Mail-Gateway-Hub é©±åŠ¨"}
                    ]
                }
            ]
        }
    }
    try:
        requests.post(webhook, json=payload, timeout=10)
    except Exception:
        logger.error("âŒ [NOTIFY] é£ä¹¦æ¨é€ç½‘ç»œå¼‚å¸¸ï¼")

# ===========================
# 3. æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
# ===========================
async def check_account(acc: Dict, global_config: Dict):
    email = acc['email']
    alias = acc.get('alias', 'Unknown')
    server = acc['imap_server']
    
    logger.info(f"ğŸ” [CONN] æ­£åœ¨æ£€æŸ¥: [{alias}] ({email})...")
    
    loop = asyncio.get_running_loop()
    try:
        def fetch_unread():
            with MailBox(server).login(email, acc['password'], initial_folder=acc.get('folder', 'INBOX')) as mb:
                msgs = []
                for m in mb.fetch(AND(seen=False)):
                    msg_date = m.date.replace(tzinfo=None)
                    if msg_date < SCRIPT_START_TIME.replace(tzinfo=None):
                        continue
                    msgs.append({
                        "uid": m.uid, "subject": m.subject, "from": m.from_,
                        "content": m.text or m.html or ""
                    })
                return msgs

        messages = await loop.run_in_executor(executor, fetch_unread)
        
        if not messages:
            logger.debug(f"âœ¨ [{alias}] æ— æ–°é‚®ä»¶ã€‚")
            return

        logger.success(f"ğŸ“© [{alias}] å‘ç° {len(messages)} å°æ–°é‚®ä»¶ï¼")

        for msg in messages:
            if is_processed(email, msg['uid']):
                continue
            ai_result = await async_call_gemini(msg['content'], global_config)
            await async_send_feishu(msg, ai_result, global_config, acc)
            save_result(email, alias, msg['uid'], ai_result)
            logger.success(f"âœ… [{alias}] å¤„ç†æˆåŠŸ: {msg['subject']}")
            await asyncio.sleep(2) # é¢‘ç‡é™åˆ¶

    except Exception:
        logger.error(f"âŒ [{alias}] è¿æ¥æˆ–å¤„ç†é”™è¯¯ï¼")
        logger.error(traceback.format_exc())

async def scheduler(config: Dict, run_once: bool = False):
    accounts = config.get('accounts', [])
    if not accounts:
        logger.error("âŒ [SYSTEM] æœªé…ç½®è´¦å·ã€‚")
        return

    if run_once:
        logger.info("ğŸ•’ [SYSTEM] æ‰§è¡Œå•æ¬¡æ‰«ææ¨¡å¼...")
        await asyncio.gather(*[check_account(acc, config) for acc in accounts])
    else:
        logger.success(f"ğŸš€ [SYSTEM] æ­£åœ¨ç›‘å¬ {len(accounts)} ä¸ªé‚®ç®±...")
        while True:
            await asyncio.gather(*[check_account(acc, config) for acc in accounts])
            logger.info("ğŸ’“ [HEARTBEAT] ç›‘å¬ä¸­ï¼Œ20ç§’åä¸‹ä¸€è½®...")
            await asyncio.sleep(20)

# ===========================
# 4. å…¥å£
# ===========================
if __name__ == "__main__":
    init_db()
    parser = argparse.ArgumentParser(description="Mail-Gateway-Hub")
    parser.add_argument("--list", action="store_true", help="æ˜¾ç¤ºæœ€è¿‘å¤„ç†è®°å½•")
    parser.add_argument("--once", action="store_true", help="å•æ¬¡æ‰«æåé€€å‡º")
    args = parser.parse_args()

    if args.list:
        stats = get_db_stats()
        print(f"\n{'æ—¶é—´':<20} | {'åˆ«å':<10} | {'åˆ†ç±»':<10} | {'æ‘˜è¦'}")
        print("-" * 100)
        for s in stats:
            print(f"{s['processed_at']:<20} | {s['alias']:<10} | {s['category']:<10} | {s['summary']}")
        print()
        sys.exit(0)

    config = load_config()
    try:
        asyncio.run(scheduler(config, run_once=args.once))
    except KeyboardInterrupt:
        logger.warning("ğŸ›‘ [SYSTEM] æœåŠ¡å·²åœæ­¢ã€‚")
